vectorstore_reader:
    kind: weaviate
    provider: dkubex
    properties:
    - paperchunks
    - dkubexfm
questions_generator:                                        # Generates the questions to be used for the dataset evaluation
    prompt_str: "default"
    prompt_file: ""
    num_questions_per_chunk: 1                              # Number of questions to be generated per chunk
    max_chunks: 100                                         # Maximum number of chunks to be used for question generation
    llm: openai                                             # Language model to be used for question generation. To use OpenAI to generate questions, use 'openai'. To use DKubeX LLM deployment, use 'dkubex'
    llmkey: "sk-4aYW**********************ZRLQe"            # If using DKubeX deployment, provide the serving_token for the deployment. If using OpenAI, provide the OpenAI API key
    llmurl: ""                                              # Endpoint URL for the DKubeX LLM deployment which will be used for generating responses. If using OpenAI, keep blank.
    max_tokens: 2048                                        # Maximum number of tokens to be used for generating questions
retrieval_evaluator:
    vector_retriever:
        kind: weaviate
        vectorstore_provider: dkubex
        textkey: paperchunks
        embedding_class: HuggingFaceEmbedding               # Use 'HuggingFaceEmbedding' for embedding models from HuggingFace, or 'OpenAIEmbedding' for OpenAI embeddings
        embedding_model: "BAAI/bge-large-en-v1.5"           # Embedding model name
        llmkey: ""                                          # API key for the embedding model (if required)
        similarity_top_k: 3
    metrics:
    - mrr
    - hit_rate
semantic_similarity_evaluator:
    prompt_str: "default"
    prompt_file: ""
    llm: dkubex                                             # Language model to be used for generating responses for semantic similarity evaluation. To use DKubeX LLM deployment, use 'dkubex'. To use OpenAI, use 'openai'
    llmkey: "eyJh******************************dJSg"        # If using DKubeX deployment for generating responses, provide the serving_token for the deployment. If using OpenAI, provide the OpenAI API key
    url: "https://123.45.67.890/deployment/1/llama27bbase/" # Endpoint URL for the DKubeX LLM deployment which will be used for generating responses. If using OpenAI, keep blank
    max_tokens: 2048                                        # Maximum number of tokens to be used for generating responses
    rag_configuration: "/absolute/path/to/rag/config"       # Absolute path to the RAG config (query.yaml) file.
    metrics:
    - similarity_score
tracking:
    experiment: dkubexfm-rag-evaluate                       # Provide MLFlow experiment name
