model_name : ""
#model identifier from huggingface.co/models (default: None)
config_name: ""
#Pretrained config name or path if not the same as model_name (default: None)
tokenizer_name: ""
#Pretrained tokenizer name or path if not the same as model_name (default: None)
cache_dir: ""
#Where do you want to store the pretrained models downloaded from s3 (default: None)
train_data: ""
#Path to train data (default: None)
train_group_size: ""
query_max_len: 32
#The maximum total input sequence length after tokenization for passage. Sequences longer than this will be truncated, sequences shorter will be padded.
#(default: 32)
passage_max_len: 128
#The maximum total input sequence length after tokenization for passage. Sequences longer than this will be truncated, sequences shorter will be padded.
#(default: 128)
max_example_num_per_dataset: 100000000
#the max number of examples for each dataset (default: 100000000)
query_instruction_for_retrieval: ""
#instruction for query (default: None)
passage_instruction_for_retrieval: ""
#instruction for passage (default: None)
output_dir: ""
#The output directory where the model predictions and checkpoints will be written. (default: None)
overwrite_output_dir: false
#Overwrite the content of the output directory. Use this to continue training if output_dir points to a checkpoint directory. (default: False)
do_train: false
#Whether to run training. (default: False)
do_eval: false   #Whether to run eval on the dev set. (default: False)
do_predict: false
#Whether to run predictions on the test set. (default: False)
eval_strategy: "no" #{no,steps,epoch}
#The evaluation strategy to use. (default: no)
prediction_loss_only: false
#When performing evaluation and predictions, only returns the loss. (default: False)
per_device_train_batch_size: 8
#Batch size per GPU/TPU/MPS/NPU core/CPU for training. (default: 8)
per_device_eval_batch_size: 8
#Batch size per GPU/TPU/MPS/NPU core/CPU for evaluation. (default: 8)
per_gpu_train_batch_size: ""
#Deprecated, the use of `per_device_train_batch_size` is preferred. Batch size per GPU/TPU core/CPU for training. (default: None)
per_gpu_eval_batch_size: ""
#Deprecated, the use of `per_device_eval_batch_size` is preferred. Batch size per GPU/TPU core/CPU for evaluation. (default: None)
gradient_accumulation_steps: 1
#Number of updates steps to accumulate before performing a backward/update pass. (default: 1)
eval_accumulation_steps: ""
#Number of predictions steps to accumulate before moving the tensors to the CPU. (default: None)
eval_delay: 0
#Number of epochs or steps to wait for before the first evaluation can be performed, depending on the eval_strategy. (default: 0)
learning_rate: "5e-05"
#The initial learning rate for AdamW. (default: 5e-05)
weight_decay: "0.0"
#Weight decay for AdamW if we apply some. (default: 0.0)
adam_beta1: "0.9"
#Beta1 for AdamW optimizer (default: 0.9)
adam_beta2: "0.999"
#Beta2 for AdamW optimizer (default: 0.999)
adam_epsilon: "1e-08"
#Epsilon for AdamW optimizer. (default: 1e-08)
max_grad_norm: "1.0"
#Max gradient norm. (default: 1.0)
num_train_epochs: "3.0"
#Total number of training epochs to perform. (default: 3.0)
max_steps: "-1"
#If > 0: set total number of training steps to perform. Override num_train_epochs. (default: -1)
lr_scheduler_type: "linear"  #{linear,cosine,cosine_with_restarts,polynomial,constant,constant_with_warmup,inverse_sqrt,reduce_lr_on_plateau,cosine_with_min_lr,warmup_stable_decay}
#The scheduler type to use. (default: linear)
lr_scheduler_kwargs: "{}"
#Extra parameters for the lr_scheduler such as {'num_cycles': 1} for the cosine with hard restarts. (default: {})
warmup_ratio: "0.0"
#Linear warmup over warmup_ratio fraction of total steps. (default: 0.0)
warmup_steps: "0"
#Linear warmup over warmup_steps. (default: 0)
log_level: "passive" #{detail,debug,info,warning,error,critical,passive}
#Logger log level to use on the main node. Possible choices are the log levels as strings: 'debug', 'info', 'warning', 'error' and 'critical', plus a
#'passive' level which doesn't set anything and lets the application set the level. Defaults to 'passive'. (default: passive)
log_level_replica: "warning" #{detail,debug,info,warning,error,critical,passive}
#Logger log level to use on replica nodes. Same choices and defaults as ``log_level`` (default: warning)
log_on_each_node: true 
#When doing a multinode distributed training, whether to log once per node or just once on the main node. (default: True)
no_log_on_each_node: false
#When doing a multinode distributed training, whether to log once per node or just once on the main node. (default: False)
logging_dir: ""
#Tensorboard log dir. (default: None)
logging_strategy: "steps" #{no,steps,epoch}
#The logging strategy to use. (default: steps)
logging_first_step: false
#Log the first global_step (default: False)
logging_steps: 500
#Log every X updates steps. Should be an integer or a float in range `[0,1)`. If smaller than 1, will be interpreted as ratio of total training steps.
#(default: 500)
logging_nan_inf_filter: true
#Filter nan and inf losses for logging. (default: True)
no_logging_nan_inf_filter: false
#Filter nan and inf losses for logging. (default: False)
save_strategy: "steps" #{no,steps,epoch}
#The checkpoint save strategy to use. (default: steps)
save_steps: 500
#Save checkpoint every X updates steps. Should be an integer or a float in range `[0,1)`. If smaller than 1, will be interpreted as ratio of total training
#steps. (default: 500)
save_total_limit: ""
#If a value is passed, will limit the total amount of checkpoints. Deletes the older checkpoints in `output_dir`. When `load_best_model_at_end` is enabled,
#the 'best' checkpoint according to `metric_for_best_model` will always be retained in addition to the most recent ones. For example, for `save_total_limit=5`
#and `load_best_model_at_end=True`, the four last checkpoints will always be retained alongside the best model. When `save_total_limit=1` and
#`load_best_model_at_end=True`, it is possible that two checkpoints are saved: the last one and the best one (if they are different). Default is unlimited
#checkpoints (default: None)
save_safetensors: true
#Use safetensors saving and loading for state dicts instead of default torch.load and torch.save. (default: True)
no_save_safetensors: false
#Use safetensors saving and loading for state dicts instead of default torch.load and torch.save. (default: False)
save_on_each_node: false
#When doing multi-node distributed training, whether to save models and checkpoints on each node, or only on the main one (default: False)
save_only_model: false
#When checkpointing, whether to only save the model, or also the optimizer, scheduler & rng state.Note that when this is true, you won't be able to resume
#training from checkpoint.This enables you to save storage by not storing the optimizer, scheduler & rng state.You can only load the model using
#from_pretrained with this option set to True. (default: False)
restore_callback_states_from_checkpoint: false  #[RESTORE_CALLBACK_STATES_FROM_CHECKPOINT]
#Whether to restore the callback states from the checkpoint. If `True`, will override callbacks passed to the `Trainer` if they exist in the checkpoint.
#(default: False)
no_cuda: false #This argument is deprecated. It will be removed in version 5.0 of ðŸ¤— Transformers. (default: False)
use_cpu: false #Whether or not to use cpu. If set to False, we will use cuda/tpu/mps/npu device if available. (default: False)
use_mps_device: false
#This argument is deprecated. `mps` device will be used if available similar to `cuda` device. It will be removed in version 5.0 of ðŸ¤— Transformers (default:
#False)
seed: 42           #Random seed that will be set at the beginning of training. (default: 42)
data_seed: ""
#Random seed to be used with data samplers. (default: None)
jit_mode_eval: false
#Whether or not to use PyTorch jit trace for inference (default: False)
use_ipex: false
#Use Intel extension for PyTorch when it is available, installation: 'https://github.com/intel/intel-extension-for-pytorch' (default: False)
bf16: false        #Whether to use bf16 (mixed) precision instead of 32-bit. Requires Ampere or higher NVIDIA architecture or using CPU (use_cpu) or Ascend NPU. This is an
#experimental API and it may change. (default: False)
fp16: false        #Whether to use fp16 (mixed) precision instead of 32-bit (default: False)
fp16_opt_level: "O1"
#For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3']. See details at https://nvidia.github.io/apex/amp.html (default: O1)
half_precision_backend: "auto"  #{auto,apex,cpu_amp}
#The backend to be used for half precision. (default: auto)
bf16_full_eval: false 
#Whether to use full bfloat16 evaluation instead of 32-bit. This is an experimental API and it may change. (default: False)
fp16_full_eval: false 
#Whether to use full float16 evaluation instead of 32-bit (default: False)
tf32: ""          #Whether to enable tf32 mode, available in Ampere and newer GPU architectures. This is an experimental API and it may change. (default: None)
local_rank: -1
#For distributed training: local_rank (default: -1)
ddp_backend: "" #{nccl,gloo,mpi,ccl,hccl,cncl}
#The backend to be used for distributed training (default: None)
tpu_num_cores: ""
#TPU: Number of TPU cores (automatically passed by launcher script) (default: None)
tpu_metrics_debug: false 
#Deprecated, the use of `debug tpu_metrics_debug` is preferred. TPU: Whether to print debug metrics (default: False)
debug: ""
#Whether or not to enable debug mode. Current options: `underflow_overflow` (Detect underflow and overflow in activations and weights), `tpu_metrics_debug`
#(print debug metrics on TPU). (default: None)
dataloader_drop_last: false 
#Drop the last incomplete batch if it is not divisible by the batch size. (default: False)
eval_steps: ""
#Run an evaluation every X steps. Should be an integer or a float in range `[0,1)`. If smaller than 1, will be interpreted as ratio of total training steps.
#(default: None)
dataloader_num_workers: 0
#Number of subprocesses to use for data loading (PyTorch only). 0 means that the data will be loaded in the main process. (default: 0)
dataloader_prefetch_factor: ""
#Number of batches loaded in advance by each worker. 2 means there will be a total of 2 * num_workers batches prefetched across all workers. Default is 2 for
#PyTorch < 2.0.0 and otherwise None. (default: None)
past_index: -1
#If >=0, uses the corresponding part of the output as the past state for next step. (default: -1)
run_name: ""   #An optional descriptor for the run. Notably used for wandb logging. (default: None)
disable_tqdm: ""
#Whether or not to disable the tqdm progress bars. (default: None)
remove_unused_columns: true
#Remove columns not required by the model when using an nlp.Dataset. (default: True)
no_remove_unused_columns: false 
#Remove columns not required by the model when using an nlp.Dataset. (default: False)
label_names: "" #LABEL_NAMES [LABEL_NAMES ...]
#The list of keys in your dictionary of inputs that correspond to the labels. (default: None)
load_best_model_at_end: false 
#Whether or not to load the best model found during training at the end of training. When this option is enabled, the best checkpoint will always be saved.
#See `save_total_limit` for more. (default: False)
metric_for_best_model: ""
#The metric to use to compare two different models. (default: None)
greater_is_better: ""
#Whether the `metric_for_best_model` should be maximized or not. (default: None)
ignore_data_skip : false 
#When resuming training, whether or not to skip the first epochs and batches to get to the same training data. (default: False)
fsdp: ""          # Whether or not to use PyTorch Fully Sharded Data Parallel (FSDP) training (in distributed training only). The base option should be `full_shard`,
#`shard_grad_op` or `no_shard` and you can add CPU-offload to `full_shard` or `shard_grad_op` like this: full_shard offload` or `shard_grad_op offload`. You
#can add auto-wrap to `full_shard` or `shard_grad_op` with the same syntax: full_shard auto_wrap` or `shard_grad_op auto_wrap`. (default: )
fsdp_min_num_params: 0
#This parameter is deprecated. FSDP's minimum number of parameters for Default Auto Wrapping. (useful only when `fsdp` field is passed). (default: 0)
fsdp_config: ""
#Config to be used with FSDP (Pytorch Fully Sharded Data Parallel). The value is either a fsdp json config file (e.g., `fsdp_config.json`) or an already
#loaded json file as `dict`. (default: None)
fsdp_transformer_layer_cls_to_wrap: ""
#This parameter is deprecated. Transformer layer class name (case-sensitive) to wrap, e.g, `BertLayer`, `GPTJBlock`, `T5Block` .... (useful only when `fsdp`
#flag is passed). (default: None)
accelerator_config: ""
#Config to be used with the internal Accelerator object initializtion. The value is either a accelerator json config file (e.g., `accelerator_config.json`) or
#an already loaded json file as `dict`. (default: None)
deepspeed: ""
#Enable deepspeed and pass the path to deepspeed json config file (e.g. `ds_config.json`) or an already loaded json file as a dict (default: None)
label_smoothing_factor: "0.0"
#The label smoothing epsilon to apply (zero means no label smoothing). (default: 0.0)
optim: "adamw_torch" #{adamw_hf,adamw_torch,adamw_torch_fused,adamw_torch_xla,adamw_torch_npu_fused,adamw_apex_fused,adafactor,adamw_anyprecision,sgd,adagrad,adamw_bnb_8bit,adamw_8bit,lion_8bit,lion_32bit,paged_adamw_32bit,paged_adamw_8bit,paged_lion_32bit,paged_lion_8bit,rmsprop,rmsprop_bnb,rmsprop_bnb_8bit,rmsprop_bnb_32bit,galore_adamw,galore_adamw_8bit,galore_adafactor,galore_adamw_layerwise,galore_adamw_8bit_layerwise,galore_adafactor_layerwise,lomo,adalomo}
#The optimizer to use. (default: adamw_torch)
optim_args: ""
#Optional arguments to supply to optimizer. (default: None)
adafactor: false
#Whether or not to replace AdamW by Adafactor. (default: False)
group_by_length: false
#Whether or not to group samples of roughly the same length together when batching. (default: False)
length_column_name: "length"
#Column name with precomputed lengths to use when grouping by length. (default: length)
report_to: ""
#The list of integrations to report the results and logs to. (default: None)
ddp_find_unused_parameters: ""
#When using distributed training, the value of the flag `find_unused_parameters` passed to `DistributedDataParallel`. (default: None)
ddp_bucket_cap_mb: ""
#When using distributed training, the value of the flag `bucket_cap_mb` passed to `DistributedDataParallel`. (default: None)
ddp_broadcast_buffers: ""
#When using distributed training, the value of the flag `broadcast_buffers` passed to `DistributedDataParallel`. (default: None)
dataloader_pin_memory: true
#Whether or not to pin memory for DataLoader. (default: True)
no_dataloader_pin_memory: false
#Whether or not to pin memory for DataLoader. (default: False)
dataloader_persistent_workers: false
#If True, the data loader will not shut down the worker processes after a dataset has been consumed once. This allows to maintain the workers Dataset
#instances alive. Can potentially speed up training, but will increase RAM usage. (default: False)
skip_memory_metrics: true
#Whether or not to skip adding of memory profiler reports to metrics. (default: True)
no_skip_memory_metrics: false
#Whether or not to skip adding of memory profiler reports to metrics. (default: False)
use_legacy_prediction_loop: false
#Whether or not to use the legacy prediction_loop in the Trainer. (default: False)
push_to_hub: false
#Whether or not to upload the trained model to the model hub after training. (default: False)
resume_from_checkpoint: ""
#The path to a folder with a valid checkpoint for your model. (default: None)
hub_model_id: ""
#The name of the repository to keep in sync with the local `output_dir`. (default: None)
hub_strategy: "every_save" #{end,every_save,checkpoint,all_checkpoints}
#The hub strategy to use when `push_to_hub` is activated. (default: every_save)
hub_token: ""
#The token to use to push to the Model Hub. (default: None)
hub_private_repo: false
#Whether the model repository is private or not. (default: False)
hub_always_push: false
#Unless `True`, the Trainer will skip pushes if the previous one wasn't finished yet. (default: False)
gradient_checkpointing: false
#If True, use gradient checkpointing to save memory at the expense of slower backward pass. (default: False)
gradient_checkpointing_kwargs: ""
#Gradient checkpointing key word arguments such as `use_reentrant`. Will be passed to `torch.utils.checkpoint.checkpoint` through
#`model.gradient_checkpointing_enable`. (default: None)
include_inputs_for_metrics: false
#Whether or not the inputs will be passed to the `compute_metrics` function. (default: False)
eval_do_concat_batches: true
#Whether to recursively concat inputs/losses/labels/predictions across batches. If `False`, will instead store them as lists, with each batch kept separate.
#(default: True)
no_eval_do_concat_batches: false
#Whether to recursively concat inputs/losses/labels/predictions across batches. If `False`, will instead store them as lists, with each batch kept separate.
#(default: False)
fp16_backend: "auto" #{auto,apex,cpu_amp}
#Deprecated. Use half_precision_backend instead (default: auto)
evaluation_strategy: "" #{no,steps,epoch}
#Deprecated. Use `eval_strategy` instead (default: None)
push_to_hub_model_id: ""
#The name of the repository to which push the `Trainer`. (default: None)
push_to_hub_organization: ""
#The name of the organization in with to which push the `Trainer`. (default: None)
push_to_hub_token: ""
#The token to use to push to the Model Hub. (default: None)
mp_parameters: ""
#Used by the SageMaker launcher to send mp-specific args. Ignored in Trainer (default: )
auto_find_batch_size: false
#Whether to automatically decrease the batch size in half and rerun the training loop again each time a CUDA Out-of-Memory was reached (default: False)
full_determinism: false
#Whether to call enable_full_determinism instead of set_seed for reproducibility in distributed training. Important: this will negatively impact the
#performance, so only use it for debugging. (default: False)
torchdynamo: ""
#This argument is deprecated, use `torch_compile_backend` instead. (default: None)
ray_scope: "last"
#The scope to use when doing hyperparameter search with Ray. By default, `"last"` will be used. Ray will then use the last checkpoint of all trials, compare
#those, and select the best one. However, other options are also available. See the Ray documentation
#(https://docs.ray.io/en/latest/tune/api_docs/analysis.html#ray.tune.ExperimentAnalysis.get_best_trial) for more options. (default: last)
ddp_timeout: 1800
#Overrides the default timeout for distributed training (value should be given in seconds). (default: 1800)
torch_compile: false
#If set to `True`, the model will be wrapped in `torch.compile`. (default: False)
torch_compile_backend: ""
#Which backend to use with `torch.compile`, passing one will trigger a model compilation. (default: None)
torch_compile_mode: ""
#Which mode to use with `torch.compile`, passing one will trigger a model compilation. (default: None)
dispatch_batches: ""
#Deprecated. Pass {'dispatch_batches':VALUE} to `accelerator_config`. (default: None)
split_batches: ""
#Deprecated. Pass {'split_batches':True} to `accelerator_config`. (default: None)
include_tokens_per_second: false
#If set to `True`, the speed metrics will include `tgs` (tokens per second per device). (default: False)
include_num_input_tokens_seen: false
#If set to `True`, will track the number of input tokens seen throughout training. (May be slower in distributed training) (default: False)
neftune_noise_alpha: ""
#Activates neftune noise embeddings into the model. NEFTune has been proven to drastically improve model performances for instrcution fine-tuning. Check out
#the original paper here: https://arxiv.org/abs/2310.05914 and the original code here: https://github.com/neelsjain/NEFTune. Only supported for
#`PreTrainedModel` and `PeftModel` classes. (default: None)
optim_target_modules: ""
#Target modules for the optimizer defined in the `optim` argument. Only used for the GaLore optimizer at the moment. (default: None)
batch_eval_metrics: false
#Break eval metrics calculation into batches to save memory. (default: False)
eval_on_start: false
#Whether to run through the entire `evaluation` step at the very beginning of training as a sanity check. (default: False)
negatives_cross_device: false
#share negatives across devices (default: False)
temperature: ""
fix_position_embedding: false
#Freeze the parameters of position embeddings (default: False)
sentence_pooling_method: "cls"
#the pooling method, should be cls or mean (default: cls)
normlized: true
no_normlized: false
use_inbatch_neg: false
#use passages in the same batch as negatives (default: True)
no_use_inbatch_neg: false  #use passages in the same batch as negatives (default: False)