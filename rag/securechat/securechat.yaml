image: "dkubex123/llmapp:securechat-0.8.7.1"
ingressprefix: "/demoapp"                                     # Provide unique ingress prefix for the application.
name: "demoapp"                                               # Unique name of the chat application
cpu: 1                                                        # default= -1
gpu: 0                                                        # default= 0
memory: 4                                                     # default= -1
dockerserver: "DOCKER_SERVER"                                 # Docker server. Default=DOCKER_SERVER
dockeruser: "dkubex123"                                       # Docker repo username. Default=DOCKER_USER
dockerpsw: "dckr_pat_dE90DkE9bzttBinnniexlHdPPgI"             # Docker repo password/access token. Default=DOCKER_PASSWORD
publish: "false"                                              # To publish the app across namespaces. OPTIONS:true/false. Default="true"
env:
 SECUREAPP_ACCESS_KEY: "allow"      
 FMQUERY_ARGS: "llm --dataset demo_dataset --config <path to RAG config>"
                            # Use 'llm' if using DKubeX LLM deployment for generating response, else use 'openai' if using OpenAI
                            # --dataset: Name of the dataset to be queried
                            # --config: Absolute path to the RAG config (query.yaml) file
port: "3000"                                                  # Port to launch the app on. Default="8080"
description: "Chat Application"
rewritetarget: "false"
configsnippet: ""                                             # default=""
output: "yaml"
mount_home: "all"
metrics:
 port: 8877
