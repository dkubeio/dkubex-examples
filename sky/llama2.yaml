name: llama2

resources:
  accelerators: A10G:1

# Assume your working directory is under `~/transformers`.
# To make this example work, please run the following command:
# git clone https://github.com/huggingface/transformers.git ~/transformers -b v4.30.1
workdir: .

envs:
  CLOUDSDK_CORE_PROJECT: dkubex
  MLFLOW_TRACKING_URI: https://<dkubexip:port>/api/mlflow/
  MLFLOW_TRACKING_INSECURE_TLS: "true"
  MLFLOW_EXPERIMENT_NAME: 'llama2_t'

setup: |
  conda create -n llama2 python=3.10 -y
  conda activate llama2
   pip install transformers==4.29.2 triton==2.0.0 sentencepiece==0.1.99 datasets==2.12.0 peft==0.3.0 torch==2.0.1 accelerate==0.19.0 safetensors==0.3.1 einops==0.6.1 wandb==0.15.3 bitsandbytes==0.39.0 scipy==1.11.1 mlflow==2.4.2 wget==3.2 fire==0.5.0 trl==0.7.1 boto3==1.28.47 ray==2.6.1 
run: |
  conda activate llama2
  python trainer.py
